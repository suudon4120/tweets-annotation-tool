# Twitter Annotation Tool

LLMによってタグ付けされたツイートを人手で検証・修正するためのアノテーションツールです。
Streamlitを使用しており、ブラウザ上で直感的に操作が可能です。

## 📁 ディレクトリ構成

- `app.py`: アプリケーション実行ファイル
- `requirements.txt`: 依存ライブラリリスト
- `src/`: アプリケーションのロジック
- `data/`: データ格納ディレクトリ
  - `raw/`: 元データ (読み取り専用)
  - `batches/`: サンプリングされた作業用データ
  - `results/`: アノテーション完了後の成果物データ

## 🚀 セットアップ手順

### 1. 環境構築
Python (3.8以上推奨) がインストールされている環境で、必要なライブラリをインストールします。

```bash
pip install -r requirements.txt
```

### 2. データの配置
`data/raw/` フォルダを作成し（存在しない場合）、元データとなるCSVファイル（`KYOTO2_batch_tagged.csv`）を配置してください。

## 🖥️ 使い方

以下のコマンドでアプリを起動します。

```bash
streamlit run app.py
```

ブラウザが自動的に立ち上がり、アプリが表示されます。

### Step 1: データセットの作成 (Sampling)
管理者または作業開始時に行います。

1. 左サイドバーで **"Sampling (データセット作成)"** モードを選択します。
2. **作業者名**（例: `taro`）、**乱数シード**（再現性確保のため）、**抽出件数**を入力します。
3. 「データセットを作成」ボタンを押すと、`data/batches/` フォルダに作業用CSVファイルが生成されます。

### Step 2: アノテーション作業 (Annotation)
作業者が行う工程です。

1. 左サイドバーで **"Annotation (タグ付け作業)"** モードを選択します。
2. プルダウンメニューから、自分の **作業用ファイル** を選択します。
3. 画面にツイートとLLMの予測タグが表示されます。
   - **位置関連性**: 正解を選択
   - **主観性・感情・属性**: ドロップダウンから正解を選択（LLMの予測がデフォルトで入っています）
4. **「保存して次へ ➡️」** を押すと、作業内容が自動保存され次のデータへ進みます。
5. 全データの確認が終わると完了画面が表示され、`data/results/` フォルダに最終結果ファイル（`result_...csv`）が保存されます。

## ⚠️ 注意事項
- `data/raw/` 内の元データは変更しないでください。
- 作業を中断しても、次回起動時に自動的に続きから再開できます。